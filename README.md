# Awesome BioChem Transformers
Favorite list on Deep Transformers Applied to Chemistry and Biology

## Table of Contents

- [Molecule Transformers](#molecule-transformers)
  - [Molecule Representation](#molecule-representation)
  - [Enzymatic Reaction](#enzymatic-reaction)
  - [Molecule Generation](#molecule-generation)
  - [Retrosynthesis Pathways](#molecule-retrosynthesis-pathways)

- [Protein Transformers](#protein-transformers)

# Molecule Transformers

## Molecule Representation
Before talking about deep learning for molecules, we need to think first about "how to represent a molecule" itself.

<img src="https://github.com/ratthachat/awesome-biochem-transformers/blob/main/pictures/molecule_rep.png" width="63%" height="63%">

- [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) : SMILES has been a standard on molecule representation using string since 1980s. As of 2022, SMILES is still a standard way to represent a molecule in machine learning. Since SMILES is a string, molecule machine learning using SMILES then can be converted to language-model machine learning. Therefore, state-of-the-arts language models like BERT, GPT and Langauge-translation Transformers are commonly seen in literatures.
 
- [SELFIES](https://github.com/aspuru-guzik-group/selfies) SELFIES
- Graph
- Beyond Graph

## Enzymatic Reaction

## Molecule Generation

## Molecule Retrosynthesis Pathways
- BioNavi NP

# Protein Transformers
- AlphaFold2
- ESMFold
- OmegaFold

## Protein-Protein Docking
- EquiDock

## Protein-Ligand Docking
- EquiBind

## Protein Generation

## Protein Design
